# -*- coding: utf-8 -*-
"""WhatsappAnalyzer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1opiHcgUBNusLNx8izi1q1MCRT3vqTsS1
"""

#import torch
import re
import pandas as pd
import matplotlib.pyplot  as plt

def startsWithDateTime(s):
    pattern = '^([0-2][0-9]|(3)[0-1])(\/)(((0)[0-9])|((1)[0-2]))(\/)\d{4}, ([0-9][0-9]):([0-9][0-9]) -'
    result = re.match(pattern, s)
    if result:
        return True
    return False

def startsWithAuthor(s):
    patterns = [
        '([\w]+):',                        # First Name
        '([\w]+[\s]+[\w]+):',              # First Name + Last Name
        '([\w]+[\s]+[\w]+[\s]+[\w]+):',    # First Name + Middle Name + Last Name
        '([+]\d{2} \d{5} \d{5}):',         # Mobile Number (India)
        '([+]\d{2} \d{3} \d{3} \d{4}):',   # Mobile Number (US)
        '([+]\d{2} \d{4} \d{7})'           # Mobile Number (Europe)
    ]
    pattern = '^' + '|'.join(patterns)
    result = re.match(pattern, s)
    if result:
        return True
    return False

def getDataPoint(line):
    # line = 18/06/17, 22:47 - Loki: Why do you have 2 numbers, Banner?
    
    splitLine = line.split(' - ') # splitLine = ['18/06/17, 22:47', 'Loki: Why do you have 2 numbers, Banner?']
    
    dateTime = splitLine[0] # dateTime = '18/06/17, 22:47'
    
    date, time = dateTime.split(', ') # date = '18/06/17'; time = '22:47'
    
    message = ' '.join(splitLine[1:]) # message = 'Loki: Why do you have 2 numbers, Banner?'
    
    if startsWithAuthor(message): # True
        splitMessage = message.split(': ') # splitMessage = ['Loki', 'Why do you have 2 numbers, Banner?']
        author = splitMessage[0] # author = 'Loki'
        message = ' '.join(splitMessage[1:]) # message = 'Why do you have 2 numbers, Banner?'
    else:
        author = None
    return date, time, author, message

parsedData = [] # List to keep track of data so it can be used by a Pandas dataframe
conversationPath = './content/sample_data/WhatsApp Chat with BYOB-Bangalore.txt' 
with open(conversationPath, encoding="utf-8") as fp:
    fp.readline() # Skipping first line of the file (usually contains information about end-to-end encryption)
        
    messageBuffer = [] # Buffer to capture intermediate output for multi-line messages
    date, time, author = None, None, None # Intermediate variables to keep track of the current message being processed
    
    count = 0
    while True:
        line = fp.readline() 
        #print(line)
        if not line or count > 50000: # Stop reading further if end of file has been reached
            break
        line = line.strip() # Guarding against erroneous leading and trailing whitespaces
        if startsWithDateTime(line): # If a line starts with a Date Time pattern, then this indicates the beginning of a new message
            if len(messageBuffer) > 0: # Check if the message buffer contains characters from previous iterations
                parsedData.append([date, time, author, ' '.join(messageBuffer)]) # Save the tokens from the previous message in parsedData
            #print(parsedData)
            messageBuffer.clear() # Clear the message buffer so that it can be used for the next message
            date, time, author, message = getDataPoint(line) # Identify and extract tokens from the line
            messageBuffer.append(message) # Append message to buffer
        else:
            messageBuffer.append(line) # If a line doesn't start with a Date Time pattern, then it is part of a multi-line message. So, just append to buffer
        count += 1

#pd is pandas library
df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message'])
df.head()

# f= open("./WhatsApp Chat with BYOB-Bangalore.txt","r")
# content=f.read()
#startsWithDateTime("18/06/17, 22:47 - Loki: Why do you have 2 numbers, Banner?")

df.tail()
#startsWithDateTime('25/09/2016, 21:50 - Pratyush BYOB created group "BYOB-Bangalore"')

df.describe()

!pip install data-anonymizer-mapper

#from anonymizer import Anonymizer
#anonymizer = Anonymizer()
#df['Author'] = df['Author'].apply(lambda s : anonymizer.get_anonymized_name(s) if s is not None else s)

df.head()

df.tail()

df.describe()

author_value_counts = df['Author'].value_counts() # Number of messages per author
top_10_author_value_counts = author_value_counts.head(10) # Number of messages per author for the top 10 most active authors
top_10_author_value_counts.plot.barh() # Plot a bar chart using pandas built-in plotting apis

null_authors_df = df[df['Author'].isnull()]
null_authors_df.head()

media_messages_df = df[df['Message'] == '<Media omitted>']

#df.shape[0] gives you the row count
print(media_messages_df.shape[0])

#gives the count of messages by each author
df['Author'].value_counts()

#gives the count of <Media omitted> messages by each author
media_messages_df['Author'].value_counts()

#gives the Top 10 author, count of <Media omitted> messages by each author
top_10_author_media_messages_value_counts = media_messages_df['Author'].value_counts().head(10)

top_10_author_media_messages_value_counts.plot.barh()

#df['Message'] == '<Media omitted>' = 1475
#df['Author'].isnull() = 361
#df = 17721
# remaining messages count => 15885

#Messages with media omitted are removed
messages_MO_df = df[df['Message'] != '<Media omitted>' ]

#messages_df = messages_MO_df[messages_MO_df['Author']]

messages_df=messages_MO_df.drop(null_authors_df.index) # Drops all rows of the data frame containing messages from null authors

print(messages_df.shape[0])

messages_df.head()

messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s: len(s))

messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))

messages_df.tail()

discrete_columns = ['Date', 'Time', 'Author', 'Message']
messages_df[discrete_columns].describe()

continuous_columns = ['Letter_Count', 'Word_Count']
messages_df[continuous_columns].describe()

messages_df['Letter_Count'].sum(), messages_df['Word_Count'].sum()

messages_ByAuthor=messages_df[['Author','Word_Count']].groupby(['Author']).sum().sort_values('Word_Count', ascending=False)

messages_ByAuthor.head(10).plot.barh()
plt.xlabel('Number of Words')
plt.ylabel('Authors')

total_word_count_grouped_by_author = messages_df[['Author', 'Word_Count']].groupby('Author').sum()
sorted_total_word_count_grouped_by_author = total_word_count_grouped_by_author.sort_values('Word_Count', ascending=False)
top_10_sorted_total_word_count_grouped_by_author = sorted_total_word_count_grouped_by_author.head(10)
top_10_sorted_total_word_count_grouped_by_author.plot.barh()
plt.xlabel('Number of Words')
plt.ylabel('Authors')

plt.figure(figsize=(15, 2)) # To ensure that the bar plot fits in the output cell of a Jupyter notebook
word_count_value_counts = messages_df['Word_Count'].value_counts().sort_values( ascending=False)
top_40_word_count_value_counts = word_count_value_counts.head(40)
top_40_word_count_value_counts.plot.bar()

plt.figure(figsize=(15, 2))
letter_Count_each_author = messages_df[['Letter_Count','Author']].groupby('Author').sum()
letter_Count_each_author.head(10).plot.bar()

